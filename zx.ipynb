{
 "cells": [
  {
   "cell_type": "raw",
   "id": "45f3fe3e-b158-4c0c-920b-6f6d4f69f307",
   "metadata": {},
   "source": [
    "i want to work with etfs and their underlying assets. i want to store the data by fetching using symbols. now tell me what are the options available to me in python to store symbols and also map them with underlying assets symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7067cc-1edb-4aca-8882-75d1838af18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_mapping = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"ICICINIFTY.NS\": \"^NSEI\",\n",
    "    \"SBIETFQLTY.NS\": \"NIFTYQLITY.NS\",  # example quality ETF\n",
    "    \"JUNIORBEES.NS\": \"^NSEJR\",         # Nifty Next 50\n",
    "    \"PSUBNKBEES.NS\": \"NIFTYPSUBANK.NS\",\n",
    "    \"MIDCAPETF.NS\": \"NIFTYMIDCAP150.NS\",\n",
    "    \"SENSEXBEES.NS\": \"^BSESN\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0daf83e3-0cf4-48f3-8606-a64178a7278e",
   "metadata": {},
   "source": [
    "next step: i want to fetch daily data from 1/1/21 to yesterday(including yesterday) of each symbol and its underlying asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405cb27b-df68-498e-ba36-5aeedb2e5442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ICICINIFTY.NS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^NSEJR']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "Fetching data for ICICINIFTY.NS and ^NSEI\n",
      "Fetching data for SBIETFQLTY.NS and NIFTYQLITY.NS\n",
      "Fetching data for JUNIORBEES.NS and ^NSEJR\n",
      "Fetching data for PSUBNKBEES.NS and NIFTYPSUBANK.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NIFTYPSUBANK.NS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NIFTYMIDCAP150.NS']: YFInvalidPeriodError(\"NIFTYMIDCAP150.NS: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SENSEXBEES.NS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MIDCAPETF.NS and NIFTYMIDCAP150.NS\n",
      "Fetching data for SENSEXBEES.NS and ^BSESN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Your ETF to underlying mapping\n",
    "etf_mapping = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"ICICINIFTY.NS\": \"^NSEI\",\n",
    "    \"SBIETFQLTY.NS\": \"NIFTYQLITY.NS\",\n",
    "    \"JUNIORBEES.NS\": \"^NSEJR\",\n",
    "    \"PSUBNKBEES.NS\": \"NIFTYPSUBANK.NS\",\n",
    "    \"MIDCAPETF.NS\": \"NIFTYMIDCAP150.NS\",\n",
    "    \"SENSEXBEES.NS\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetch and store data\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping.items():\n",
    "    print(f\"Fetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"etf_data\": etf_df,\n",
    "            \"underlying_data\": underlying_df\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {etf} or {underlying}: {e}\")\n",
    "\n",
    "# Example access\n",
    "# print(etf_data[\"NIFTYBEES.NS\"][\"etf_data\"].head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfa9c17a-2c69-4fd4-96d1-3e826ffaf3be",
   "metadata": {},
   "source": [
    "manual update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6001b6-28c8-4aae-9681-584b503d4de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Your ETF to underlying mapping\n",
    "etf_mapping = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetch and store data\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping.items():\n",
    "    print(f\"Fetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"etf_data\": etf_df,\n",
    "            \"underlying_data\": underlying_df\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {etf} or {underlying}: {e}\")\n",
    "\n",
    "# Example access\n",
    "# print(etf_data[\"NIFTYBEES.NS\"][\"etf_data\"].head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "710ac0c0-8f23-42d7-9d82-943a5764a50c",
   "metadata": {},
   "source": [
    "i want to check is it printing correct date range + print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b015789-810e-4003-b3cc-401944a377fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "\n",
      "===== NIFTYBEES.NS vs ^NSEI =====\n",
      "\n",
      "ETF Data (first 5 rows):\n",
      "Price              Open        Close       Volume\n",
      "Ticker     NIFTYBEES.NS NIFTYBEES.NS NIFTYBEES.NS\n",
      "Date                                             \n",
      "2021-01-01   159.679993   149.570007       767502\n",
      "2021-01-04   150.589996   150.710007      1729074\n",
      "2021-01-05   159.699997   151.300003      2248517\n",
      "2021-01-06   159.699997   151.220001      1890161\n",
      "2021-01-07   155.000000   151.199997      1184831\n",
      "\n",
      "ETF Data (last 5 rows):\n",
      "Price              Open        Close       Volume\n",
      "Ticker     NIFTYBEES.NS NIFTYBEES.NS NIFTYBEES.NS\n",
      "Date                                             \n",
      "2025-04-04   260.480011   257.160004      9233464\n",
      "2025-04-07   264.850006   249.100006     34654934\n",
      "2025-04-08   256.549988   252.720001      9860513\n",
      "2025-04-09   251.720001   251.029999      7144236\n",
      "2025-04-11   255.990005   255.970001     10802170\n",
      "\n",
      "Underlying Data (first 5 rows):\n",
      "Price               Open         Close  Volume\n",
      "Ticker             ^NSEI         ^NSEI   ^NSEI\n",
      "Date                                          \n",
      "2021-01-01  13996.099609  14018.500000  358100\n",
      "2021-01-04  14104.349609  14132.900391  495000\n",
      "2021-01-05  14075.150391  14199.500000  492500\n",
      "2021-01-06  14240.950195  14146.250000  632300\n",
      "2021-01-07  14253.750000  14137.349609  559200\n",
      "\n",
      "Underlying Data (last 5 rows):\n",
      "Price               Open         Close  Volume\n",
      "Ticker             ^NSEI         ^NSEI   ^NSEI\n",
      "Date                                          \n",
      "2025-04-04  23190.400391  22904.449219  466800\n",
      "2025-04-07  21758.400391  22161.599609  647100\n",
      "2025-04-08  22446.750000  22535.849609  468300\n",
      "2025-04-09  22460.300781  22399.150391  383800\n",
      "2025-04-11  22695.400391  22828.550781  402200\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "\n",
      "===== BANKBEES.NS vs ^NSEBANK =====\n",
      "\n",
      "ETF Data (first 5 rows):\n",
      "Price             Open       Close      Volume\n",
      "Ticker     BANKBEES.NS BANKBEES.NS BANKBEES.NS\n",
      "Date                                          \n",
      "2021-01-01  314.350006  313.649994      308206\n",
      "2021-01-04  316.000000  314.119995      737195\n",
      "2021-01-05  313.209991  318.730011      770683\n",
      "2021-01-06  320.640015  319.670013      608840\n",
      "2021-01-07  325.000000  321.079987      748450\n",
      "\n",
      "ETF Data (last 5 rows):\n",
      "Price             Open       Close      Volume\n",
      "Ticker     BANKBEES.NS BANKBEES.NS BANKBEES.NS\n",
      "Date                                          \n",
      "2025-04-04   532.00000  528.979980     1534911\n",
      "2025-04-07   527.00000  513.460022     1841036\n",
      "2025-04-08   519.97998  518.630005      970866\n",
      "2025-04-09   515.02002  516.109985      886325\n",
      "2025-04-11   520.98999  522.840027      806992\n",
      "\n",
      "Underlying Data (first 5 rows):\n",
      "Price               Open         Close   Volume\n",
      "Ticker          ^NSEBANK      ^NSEBANK ^NSEBANK\n",
      "Date                                           \n",
      "2021-01-04  31484.783935  31212.085938        0\n",
      "2021-01-05  31040.738395  31721.880859        0\n",
      "2021-01-06  31839.579590  31797.531250        0\n",
      "2021-01-07  32129.427669  31955.628906        0\n",
      "2021-01-08  32297.675248  32083.826172        0\n",
      "\n",
      "Underlying Data (last 5 rows):\n",
      "Price               Open         Close   Volume\n",
      "Ticker          ^NSEBANK      ^NSEBANK ^NSEBANK\n",
      "Date                                           \n",
      "2025-04-04  51711.601562  51502.699219   189600\n",
      "2025-04-07  49336.101562  49860.101562   236800\n",
      "2025-04-08  50388.550781  50511.000000   162300\n",
      "2025-04-09  50487.101562  50240.148438   141800\n",
      "2025-04-11  50634.101562  51002.351562   140000\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "\n",
      "===== JUNIORBEES.NS vs ^NSMIDCP =====\n",
      "\n",
      "ETF Data (first 5 rows):\n",
      "Price               Open         Close        Volume\n",
      "Ticker     JUNIORBEES.NS JUNIORBEES.NS JUNIORBEES.NS\n",
      "Date                                                \n",
      "2021-01-01    345.000000    342.190002        101472\n",
      "2021-01-04    354.000000    346.619995         94333\n",
      "2021-01-05    354.000000    351.380005        616888\n",
      "2021-01-06    359.000000    353.290009         87070\n",
      "2021-01-07    368.100006    354.730011         62490\n",
      "\n",
      "ETF Data (last 5 rows):\n",
      "Price               Open         Close        Volume\n",
      "Ticker     JUNIORBEES.NS JUNIORBEES.NS JUNIORBEES.NS\n",
      "Date                                                \n",
      "2025-04-04    678.989990    658.500000        670078\n",
      "2025-04-07    678.250000    640.000000       1812281\n",
      "2025-04-08    659.200012    651.090027        530625\n",
      "2025-04-09    666.450012    649.820007        270401\n",
      "2025-04-11    669.299988    658.320007        486347\n",
      "\n",
      "Underlying Data (first 5 rows):\n",
      "Price               Open         Close   Volume\n",
      "Ticker          ^NSMIDCP      ^NSMIDCP ^NSMIDCP\n",
      "Date                                           \n",
      "2021-01-04  32998.325655  33281.019531        0\n",
      "2021-01-05  33219.171502  33818.109375        0\n",
      "2021-01-06  33950.554880  33754.859375        0\n",
      "2021-01-07  34073.855875  33888.710938        0\n",
      "2021-01-08  34123.453151  34330.398438        0\n",
      "\n",
      "Underlying Data (last 5 rows):\n",
      "Price               Open         Close   Volume\n",
      "Ticker          ^NSMIDCP      ^NSMIDCP ^NSMIDCP\n",
      "Date                                           \n",
      "2025-04-04  63090.050781  61468.699219     3100\n",
      "2025-04-07  57256.550781  59546.199219     3500\n",
      "2025-04-08  60665.250000  60807.550781     2500\n",
      "2025-04-09  60779.800781  60664.601562     2100\n",
      "2025-04-11  61839.148438  61473.550781     2200\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n",
      "\n",
      "===== SENSEXBEES.BO vs ^BSESN =====\n",
      "\n",
      "ETF Data (first 5 rows):\n",
      "Price               Open         Close        Volume\n",
      "Ticker     SENSEXBEES.BO SENSEXBEES.BO SENSEXBEES.BO\n",
      "Date                                                \n",
      "2021-01-01    507.049988    515.070007           164\n",
      "2021-01-04    510.000000    518.359985           267\n",
      "2021-01-05    515.000000    519.150024          1026\n",
      "2021-01-06    525.000000    520.770020           206\n",
      "2021-01-07    523.039978    518.250000            32\n",
      "\n",
      "ETF Data (last 5 rows):\n",
      "Price               Open         Close        Volume\n",
      "Ticker     SENSEXBEES.BO SENSEXBEES.BO SENSEXBEES.BO\n",
      "Date                                                \n",
      "2025-04-04    859.000000    854.030029         10273\n",
      "2025-04-07    851.000000    827.200012         29738\n",
      "2025-04-08    844.979980    840.359985          6291\n",
      "2025-04-09    844.979980    835.570007          2205\n",
      "2025-04-11    841.119995    850.250000          4319\n",
      "\n",
      "Underlying Data (first 5 rows):\n",
      "Price               Open         Close Volume\n",
      "Ticker            ^BSESN        ^BSESN ^BSESN\n",
      "Date                                         \n",
      "2021-01-01  47785.281250  47868.980469  82700\n",
      "2021-01-04  48109.171875  48176.800781  13900\n",
      "2021-01-05  48037.628906  48437.781250  12200\n",
      "2021-01-06  48616.660156  48174.058594  22500\n",
      "2021-01-07  48524.359375  48093.320312  18400\n",
      "\n",
      "Underlying Data (last 5 rows):\n",
      "Price               Open         Close Volume\n",
      "Ticker            ^BSESN        ^BSESN ^BSESN\n",
      "Date                                         \n",
      "2025-04-04  76160.093750  75364.687500  11700\n",
      "2025-04-07  71449.937500  73137.898438  29400\n",
      "2025-04-08  74013.726562  74227.078125  17100\n",
      "2025-04-09  74103.828125  73847.148438   9100\n",
      "2025-04-11  74835.492188  75157.257812  14200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for etf in etf_data:\n",
    "    etf_df = etf_data[etf][\"etf_data\"]\n",
    "    underlying_df = etf_data[etf][\"underlying_data\"]\n",
    "\n",
    "    print(f\"\\n===== {etf} vs {etf_mapping[etf]} =====\")\n",
    "    print(f\"\\nETF Data (first 5 rows):\")\n",
    "    print(etf_df[['Open', 'Close', 'Volume']].head())\n",
    "\n",
    "    print(f\"\\nETF Data (last 5 rows):\")\n",
    "    print(etf_df[['Open', 'Close', 'Volume']].tail())\n",
    "\n",
    "    print(f\"\\nUnderlying Data (first 5 rows):\")\n",
    "    print(underlying_df[['Open', 'Close', 'Volume']].head())\n",
    "\n",
    "    print(f\"\\nUnderlying Data (last 5 rows):\")\n",
    "    print(underlying_df[['Open', 'Close', 'Volume']].tail())\n",
    "\"\"\"\n",
    "\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Your ETF to underlying mapping\n",
    "etf_mapping = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetch and store data\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping.items():\n",
    "    print(f\"Fetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)\n",
    "\n",
    "        #etf_df = etf_data[etf][\"etf_data\"]\n",
    "        #underlying_df = etf_data[etf][\"underlying_data\"]\n",
    "\n",
    "        print(f\"\\n===== {etf} vs {etf_mapping[etf]} =====\")\n",
    "        print(f\"\\nETF Data (first 5 rows):\")\n",
    "        print(etf_df[['Open', 'Close', 'Volume']].head())\n",
    "\n",
    "        print(f\"\\nETF Data (last 5 rows):\")\n",
    "        print(etf_df[['Open', 'Close', 'Volume']].tail())\n",
    "\n",
    "        print(f\"\\nUnderlying Data (first 5 rows):\")\n",
    "        print(underlying_df[['Open', 'Close', 'Volume']].head())\n",
    "\n",
    "        print(f\"\\nUnderlying Data (last 5 rows):\")\n",
    "        print(underlying_df[['Open', 'Close', 'Volume']].tail())\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"etf_data\": etf_df,\n",
    "            \"underlying_data\": underlying_df\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {etf} or {underlying}: {e}\")\n",
    "\n",
    "# Example access\n",
    "# print(etf_data[\"NIFTYBEES.NS\"][\"etf_data\"].head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0a397a2-aa1d-4113-81b4-f0d3cf8a4c92",
   "metadata": {},
   "source": [
    "after fetching the data i want only Open, Close, Volume for further functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48357a0a-4ff4-43bc-bc6b-0a634e6462ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ICICINIFTY.NS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^NSEJR']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "Fetching data for ICICINIFTY.NS and ^NSEI\n",
      "Fetching data for SBIETFQLTY.NS and NIFTYQLITY.NS\n",
      "Fetching data for JUNIORBEES.NS and ^NSEJR\n",
      "Fetching data for PSUBNKBEES.NS and NIFTYPSUBANK.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['NIFTYPSUBANK.NS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NIFTYMIDCAP150.NS']: YFInvalidPeriodError(\"NIFTYMIDCAP150.NS: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SENSEXBEES.NS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MIDCAPETF.NS and NIFTYMIDCAP150.NS\n",
      "Fetching data for SENSEXBEES.NS and ^BSESN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF to Underlying symbol mapping\n",
    "etf_mapping = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"ICICINIFTY.NS\": \"^NSEI\",\n",
    "    \"SBIETFQLTY.NS\": \"NIFTYQLITY.NS\",\n",
    "    \"JUNIORBEES.NS\": \"^NSEJR\",\n",
    "    \"PSUBNKBEES.NS\": \"NIFTYPSUBANK.NS\",\n",
    "    \"MIDCAPETF.NS\": \"NIFTYMIDCAP150.NS\",\n",
    "    \"SENSEXBEES.NS\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Data container\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping.items():\n",
    "    print(f\"Fetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        # Fetch and filter relevant columns only\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Open', 'Close', 'Volume']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Open', 'Close', 'Volume']]\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"etf_data\": etf_df,\n",
    "            \"underlying_data\": underlying_df\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {etf} or {underlying}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f17d13aa-12ab-44aa-885e-59b180706775",
   "metadata": {},
   "source": [
    "manual update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47012a63-8c15-406f-8017-4906c007b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF to Underlying asset symbol mapping for Yahoo Finance\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetch and store data\n",
    "# Data container\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping_yf.items():\n",
    "    print(f\"Fetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        # Fetch and filter relevant columns only\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Open', 'Close', 'Volume']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Open', 'Close', 'Volume']]\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"etf_data\": etf_df,\n",
    "            \"underlying_data\": underlying_df\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {etf} or {underlying}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69a7f129-1431-49b2-99b2-beaa296eb85f",
   "metadata": {},
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF to Underlying asset symbol mapping for Yahoo Finance\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetch and store data\n",
    "# Data container\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping_yf.items():\n",
    "    print(f\"Fetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        # Fetch and filter relevant columns only\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Open', 'Close', 'Volume']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Open', 'Close', 'Volume']]\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"etf_data\": etf_df,\n",
    "            \"underlying_data\": underlying_df\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {etf} or {underlying}: {e}\")\n",
    "\n",
    "analyze the above code and write and include the functionlity to find correlation between underlying asset and etf based on daily closing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42b1bfd4-8695-4c8b-b5fc-4b8c4970da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "Error fetching or processing data for NIFTYBEES.NS or ^NSEI: 'Close_etf'\n",
      "\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "Error fetching or processing data for BANKBEES.NS or ^NSEBANK: 'Close_etf'\n",
      "\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "Error fetching or processing data for JUNIORBEES.NS or ^NSMIDCP: 'Close_etf'\n",
      "\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n",
      "Error fetching or processing data for SENSEXBEES.BO or ^BSESN: 'Close_etf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF to Underlying asset symbol mapping for Yahoo Finance\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetch and store data\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping_yf.items():\n",
    "    print(f\"\\nFetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        # Fetch and keep only required columns\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Close']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Close']]\n",
    "\n",
    "        # Align by date (inner join on index)\n",
    "        combined_df = etf_df.join(underlying_df, lsuffix='_etf', rsuffix='_underlying', how='inner')\n",
    "\n",
    "        # Compute Pearson correlation on 'Close' prices\n",
    "        correlation = combined_df['Close_etf'].corr(combined_df['Close_underlying'])\n",
    "\n",
    "        # Store data\n",
    "        etf_data[etf] = {\n",
    "            \"combined_data\": combined_df,\n",
    "            \"correlation\": correlation\n",
    "        }\n",
    "\n",
    "        print(f\"Correlation between {etf} and {underlying}: {correlation:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching or processing data for {etf} or {underlying}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf6b48c8-2265-4787-bcb7-3d897a3e1540",
   "metadata": {},
   "source": [
    "above error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e29353c2-b89a-4071-ba2a-1653573d6fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "‚ùå Error with NIFTYBEES.NS or ^NSEI: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "‚ùå Error with BANKBEES.NS or ^NSEBANK: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "‚ùå Error with JUNIORBEES.NS or ^NSMIDCP: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n",
      "‚ùå Error with SENSEXBEES.BO or ^BSESN: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF to Underlying asset symbol mapping\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping_yf.items():\n",
    "    print(f\"\\nFetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        # Fetch closing prices\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Close']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Close']]\n",
    "\n",
    "        # Check if both datasets are not empty\n",
    "        if etf_df.empty:\n",
    "            print(f\"  ‚ö†Ô∏è ETF data not found for {etf}\")\n",
    "            continue\n",
    "        if underlying_df.empty:\n",
    "            print(f\"  ‚ö†Ô∏è Underlying data not found for {underlying}\")\n",
    "            continue\n",
    "\n",
    "        # Align and rename columns\n",
    "        etf_df = etf_df.rename(columns={'Close': 'Close_etf'})\n",
    "        underlying_df = underlying_df.rename(columns={'Close': 'Close_underlying'})\n",
    "\n",
    "        combined_df = etf_df.join(underlying_df, how='inner')\n",
    "\n",
    "        if combined_df.empty:\n",
    "            print(\"  ‚ö†Ô∏è No overlapping trading days.\")\n",
    "            continue\n",
    "\n",
    "        # Correlation\n",
    "        correlation = combined_df['Close_etf'].corr(combined_df['Close_underlying'])\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"combined_data\": combined_df,\n",
    "            \"correlation\": correlation\n",
    "        }\n",
    "\n",
    "        print(f\"‚úÖ Correlation between {etf} and {underlying}: {correlation:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {etf} or {underlying}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11aa6ca6-3244-44ec-b585-b82bc4af96fe",
   "metadata": {},
   "source": [
    "above error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6bcf84-a0ba-4566-8827-7ded536ec243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "  ‚úÖ ETF data shape: (1057, 1)\n",
      "  ‚úÖ Underlying data shape: (1056, 1)\n",
      "  üîÅ Joining dataframes...\n",
      "  ‚úÖ Combined dataframe shape: (1056, 2)\n",
      "  ‚úÖ Combined dataframe columns: MultiIndex([(       'Close_etf', 'NIFTYBEES.NS'),\n",
      "            ('Close_underlying',        '^NSEI')],\n",
      "           names=['Price', 'Ticker'])\n",
      "‚ùå Error with NIFTYBEES.NS or ^NSEI: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "  ‚úÖ ETF data shape: (1057, 1)\n",
      "  ‚úÖ Underlying data shape: (1051, 1)\n",
      "  üîÅ Joining dataframes...\n",
      "  ‚úÖ Combined dataframe shape: (1051, 2)\n",
      "  ‚úÖ Combined dataframe columns: MultiIndex([(       'Close_etf', 'BANKBEES.NS'),\n",
      "            ('Close_underlying',    '^NSEBANK')],\n",
      "           names=['Price', 'Ticker'])\n",
      "‚ùå Error with BANKBEES.NS or ^NSEBANK: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "  ‚úÖ ETF data shape: (1057, 1)\n",
      "  ‚úÖ Underlying data shape: (1051, 1)\n",
      "  üîÅ Joining dataframes...\n",
      "  ‚úÖ Combined dataframe shape: (1051, 2)\n",
      "  ‚úÖ Combined dataframe columns: MultiIndex([(       'Close_etf', 'JUNIORBEES.NS'),\n",
      "            ('Close_underlying',      '^NSMIDCP')],\n",
      "           names=['Price', 'Ticker'])\n",
      "‚ùå Error with JUNIORBEES.NS or ^NSMIDCP: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n",
      "  ‚úÖ ETF data shape: (1036, 1)\n",
      "  ‚úÖ Underlying data shape: (1054, 1)\n",
      "  üîÅ Joining dataframes...\n",
      "  ‚úÖ Combined dataframe shape: (1033, 2)\n",
      "  ‚úÖ Combined dataframe columns: MultiIndex([(       'Close_etf', 'SENSEXBEES.BO'),\n",
      "            ('Close_underlying',        '^BSESN')],\n",
      "           names=['Price', 'Ticker'])\n",
      "‚ùå Error with SENSEXBEES.BO or ^BSESN: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ETF to Underlying asset symbol mapping\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# Dynamic date range\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping_yf.items():\n",
    "    print(f\"\\nFetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Close']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Close']]\n",
    "\n",
    "        print(f\"  ‚úÖ ETF data shape: {etf_df.shape}\")\n",
    "        print(f\"  ‚úÖ Underlying data shape: {underlying_df.shape}\")\n",
    "\n",
    "        if etf_df.empty:\n",
    "            print(f\"  ‚ö†Ô∏è ETF data not found for {etf}\")\n",
    "            continue\n",
    "        if underlying_df.empty:\n",
    "            print(f\"  ‚ö†Ô∏è Underlying data not found for {underlying}\")\n",
    "            continue\n",
    "\n",
    "        etf_df.rename(columns={'Close': 'Close_etf'}, inplace=True)\n",
    "        underlying_df.rename(columns={'Close': 'Close_underlying'}, inplace=True)\n",
    "\n",
    "        print(\"  üîÅ Joining dataframes...\")\n",
    "        combined_df = etf_df.join(underlying_df, how='inner')\n",
    "\n",
    "        print(f\"  ‚úÖ Combined dataframe shape: {combined_df.shape}\")\n",
    "        print(f\"  ‚úÖ Combined dataframe columns: {combined_df.columns}\")\n",
    "\n",
    "        if combined_df.empty:\n",
    "            print(\"  ‚ö†Ô∏è No overlapping trading days.\")\n",
    "            continue\n",
    "\n",
    "        correlation = combined_df['Close_etf'].corr(combined_df['Close_underlying'])\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"combined_data\": combined_df,\n",
    "            \"correlation\": correlation\n",
    "        }\n",
    "\n",
    "        print(f\"‚úÖ Correlation between {etf} and {underlying}: {correlation:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {etf} or {underlying}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83004844-a857-4145-881e-3deade8bfc7b",
   "metadata": {},
   "source": [
    "above error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa7795df-78b5-4c50-a2a8-88fb7ded5b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for NIFTYBEES.NS and ^NSEI\n",
      "‚úÖ Correlation between NIFTYBEES.NS and ^NSEI: 0.9996\n",
      "\n",
      "Fetching data for BANKBEES.NS and ^NSEBANK\n",
      "‚úÖ Correlation between BANKBEES.NS and ^NSEBANK: 0.9997\n",
      "\n",
      "Fetching data for JUNIORBEES.NS and ^NSMIDCP\n",
      "‚úÖ Correlation between JUNIORBEES.NS and ^NSMIDCP: 0.9998\n",
      "\n",
      "Fetching data for SENSEXBEES.BO and ^BSESN\n",
      "‚úÖ Correlation between SENSEXBEES.BO and ^BSESN: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "etf_data = {}\n",
    "\n",
    "for etf, underlying in etf_mapping_yf.items():\n",
    "    print(f\"\\nFetching data for {etf} and {underlying}\")\n",
    "    try:\n",
    "        etf_df = yf.download(etf, start=start_date, end=end_date)[['Close']]\n",
    "        underlying_df = yf.download(underlying, start=start_date, end=end_date)[['Close']]\n",
    "\n",
    "        if etf_df.empty:\n",
    "            print(f\"  ‚ö†Ô∏è ETF data not found for {etf}\")\n",
    "            continue\n",
    "        if underlying_df.empty:\n",
    "            print(f\"  ‚ö†Ô∏è Underlying data not found for {underlying}\")\n",
    "            continue\n",
    "\n",
    "        # Rename flat columns (flattening from MultiIndex)\n",
    "        etf_df.columns = ['Close_etf']\n",
    "        underlying_df.columns = ['Close_underlying']\n",
    "\n",
    "        # Join on dates\n",
    "        combined_df = etf_df.join(underlying_df, how='inner')\n",
    "\n",
    "        if combined_df.empty:\n",
    "            print(\"  ‚ö†Ô∏è No overlapping trading days.\")\n",
    "            continue\n",
    "\n",
    "        correlation = combined_df['Close_etf'].corr(combined_df['Close_underlying'])\n",
    "\n",
    "        etf_data[etf] = {\n",
    "            \"combined_data\": combined_df,\n",
    "            \"correlation\": correlation\n",
    "        }\n",
    "\n",
    "        print(f\"‚úÖ Correlation between {etf} and {underlying}: {correlation:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {etf} or {underlying}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e65597ed-084a-4b4a-8967-11513304fef3",
   "metadata": {},
   "source": [
    "Gemini \n",
    "create dictionary name etf_mapping_yf and store etf and its underlying asset \n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\",\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "then using yahoofinance fetch the all the daily data (open, high, low, close, etc. ) in daily interval from 1/1/21 to yesterday(dynamic change everyday). print staring and ending data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d1038a8-3ca1-440d-9440-80268e5782d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  8 of 8 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Daily ETF and Index Data ---\n",
      "\n",
      "Fetching data from Start Date: 2021-01-01 to End Date (exclusive): 2025-04-13\n",
      "(Data requested up to yesterday: 2025-04-12)\n",
      "\n",
      "Tickers to fetch: ['BANKBEES.NS', 'JUNIORBEES.NS', 'NIFTYBEES.NS', 'SENSEXBEES.BO', '^BSESN', '^NSEBANK', '^NSEI', '^NSMIDCP']\n",
      "\n",
      "Attempting to download data...\n",
      "\n",
      "Data download attempt complete.\n",
      " - Stored data for BANKBEES.NS\n",
      " - Stored data for JUNIORBEES.NS\n",
      " - Stored data for NIFTYBEES.NS\n",
      " - Stored data for SENSEXBEES.BO\n",
      " - Stored data for ^BSESN\n",
      " - Stored data for ^NSEBANK\n",
      " - Stored data for ^NSEI\n",
      " - Stored data for ^NSMIDCP\n",
      "\n",
      "--- Fetching Process Finished ---\n",
      "Successfully fetched and stored data for 8 tickers.\n",
      "Tickers stored: ['BANKBEES.NS', 'JUNIORBEES.NS', 'NIFTYBEES.NS', 'SENSEXBEES.BO', '^BSESN', '^NSEBANK', '^NSEI', '^NSMIDCP']\n",
      "\n",
      "Example Data for NIFTYBEES.NS:\n",
      "--- Head ---\n",
      "| Date                | Close   | High   | Low    | Open   | Volume      |\n",
      "|:--------------------|:--------|:-------|:-------|:-------|:------------|\n",
      "| 2021-01-01 00:00:00 | 149.57  | 159.68 | 147.65 | 159.68 | 767502      |\n",
      "| 2021-01-04 00:00:00 | 150.71  | 150.9  | 148.95 | 150.59 | 1.72907e+06 |\n",
      "| 2021-01-05 00:00:00 | 151.3   | 159.7  | 149.75 | 159.7  | 2.24852e+06 |\n",
      "| 2021-01-06 00:00:00 | 151.22  | 159.7  | 145.58 | 159.7  | 1.89016e+06 |\n",
      "| 2021-01-07 00:00:00 | 151.2   | 155    | 151.01 | 155    | 1.18483e+06 |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Close   | High   | Low    | Open   | Volume      |\n",
      "|:--------------------|:--------|:-------|:-------|:-------|:------------|\n",
      "| 2025-04-04 00:00:00 | 257.16  | 260.58 | 256.48 | 260.48 | 9.23346e+06 |\n",
      "| 2025-04-07 00:00:00 | 249.1   | 264.85 | 231.3  | 264.85 | 3.46549e+07 |\n",
      "| 2025-04-08 00:00:00 | 252.72  | 256.55 | 249.76 | 256.55 | 9.86051e+06 |\n",
      "| 2025-04-09 00:00:00 | 251.03  | 252.68 | 250.62 | 251.72 | 7.14424e+06 |\n",
      "| 2025-04-11 00:00:00 | 255.97  | 256.9  | 251.23 | 255.99 | 1.08022e+07 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/n9/5kqrvys91_xcpbr75rhw3s9c0000gn/T/ipykernel_32975/970239479.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ticker.dropna(how='all', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"--- Fetching Daily ETF and Index Data ---\")\n",
    "\n",
    "# 1. Define the ETF to Underlying Index Mapping (Yahoo Finance Tickers)\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",      # Nifty 50 ETF vs Nifty 50 Index\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",   # Nifty Bank ETF vs Nifty Bank Index\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\", # Nifty Next 50 ETF vs Nifty Next 50 Index (*Note: User provided ^NSMIDCP, corrected to likely intended ^CNXNIITY for Nifty Next 50*)\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",    # Sensex ETF vs Sensex Index\n",
    "}\n",
    "# *Self-Correction Note:* The user originally provided \"^NSMIDCP\" for JuniorBeES.\n",
    "# JuniorBeES tracks the Nifty Next 50 index, commonly represented by \"^CNXNIITY\" on Yahoo Finance.\n",
    "# I have used \"^CNXNIITY\" assuming that was the intent. If you specifically need \"^NSMIDCP\", please adjust the dictionary.\n",
    "\n",
    "# 2. Define Date Range\n",
    "end_date = datetime.now().date() # Use today's date\n",
    "yesterday = end_date - timedelta(days=1)\n",
    "start_date = datetime(2021, 1, 1).date()\n",
    "\n",
    "# Format dates as strings for yfinance\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "# yfinance 'end' date is exclusive, so use today's date to include yesterday's data\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nFetching data from Start Date: {start_str} to End Date (exclusive): {end_str}\")\n",
    "print(f\"(Data requested up to yesterday: {yesterday.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "# 3. Prepare list of all unique tickers to fetch\n",
    "all_tickers = list(etf_mapping_yf.keys()) + list(etf_mapping_yf.values())\n",
    "unique_tickers = sorted(list(set(all_tickers)))\n",
    "\n",
    "print(f\"\\nTickers to fetch: {unique_tickers}\")\n",
    "\n",
    "# 4. Fetch Data\n",
    "all_data = {} # Dictionary to store fetched dataframes\n",
    "\n",
    "print(\"\\nAttempting to download data...\")\n",
    "try:\n",
    "    # Fetch all data in one go (more efficient)\n",
    "    # yfinance returns a Pandas Panel (or DataFrame with MultiIndex columns)\n",
    "    data_panel = yf.download(unique_tickers, start=start_str, end=end_str, progress=True)\n",
    "\n",
    "    if data_panel.empty:\n",
    "        print(\"\\nError: No data fetched. Check tickers and date range.\")\n",
    "    elif isinstance(data_panel.columns, pd.MultiIndex):\n",
    "        print(\"\\nData download attempt complete.\")\n",
    "        # Store individual DataFrames\n",
    "        for ticker in unique_tickers:\n",
    "             # Check if ticker data exists (might fail for specific tickers)\n",
    "            if ticker in data_panel.columns.get_level_values(1):\n",
    "                df_ticker = data_panel.iloc[:, data_panel.columns.get_level_values(1)==ticker]\n",
    "                # Remove the top level ticker index from columns\n",
    "                df_ticker.columns = df_ticker.columns.droplevel(1)\n",
    "                # Remove rows where all values are NaN (can happen for specific dates/tickers)\n",
    "                df_ticker.dropna(how='all', inplace=True)\n",
    "                if not df_ticker.empty:\n",
    "                    all_data[ticker] = df_ticker\n",
    "                    print(f\" - Stored data for {ticker}\")\n",
    "                else:\n",
    "                    print(f\" - Warning: No data returned/available for {ticker} in the date range after cleaning.\")\n",
    "            else:\n",
    "                 print(f\" - Warning: Could not find data for {ticker} in downloaded panel.\")\n",
    "    else:\n",
    "         # Handle case where only one ticker might have downloaded successfully\n",
    "         print(\"\\nData download attempt complete (possibly for a single ticker).\")\n",
    "         if not data_panel.empty:\n",
    "             # Assuming the single ticker is the only one requested or downloaded\n",
    "             ticker = unique_tickers[0] # Assumption\n",
    "             data_panel.dropna(how='all', inplace=True)\n",
    "             if not data_panel.empty:\n",
    "                 all_data[ticker] = data_panel\n",
    "                 print(f\" - Stored data for {ticker}\")\n",
    "             else:\n",
    "                print(f\" - Warning: No data returned/available for {ticker} in the date range after cleaning.\")\n",
    "         else:\n",
    "             print(\" - Fetched panel is empty.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during data fetching: {e}\")\n",
    "    print(\"Please ensure libraries are installed and check internet connection.\")\n",
    "\n",
    "# 5. Confirmation and Example Output\n",
    "print(\"\\n--- Fetching Process Finished ---\")\n",
    "if all_data:\n",
    "    print(f\"Successfully fetched and stored data for {len(all_data)} tickers.\")\n",
    "    print(\"Tickers stored:\", list(all_data.keys()))\n",
    "\n",
    "    # Print head and tail of one example DataFrame (e.g., NIFTYBEES.NS)\n",
    "    example_ticker = \"NIFTYBEES.NS\"\n",
    "    if example_ticker in all_data:\n",
    "        print(f\"\\nExample Data for {example_ticker}:\")\n",
    "        print(\"--- Head ---\")\n",
    "        print(all_data[example_ticker].head().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "        print(\"\\n--- Tail ---\")\n",
    "        print(all_data[example_ticker].tail().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "    else:\n",
    "        print(f\"\\nExample ticker {example_ticker} not found in fetched data.\")\n",
    "else:\n",
    "    print(\"No data was successfully stored.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ea44da6-1f1d-4936-afcd-16c63c6e1273",
   "metadata": {},
   "source": [
    "fine. next step is fetch only open close and volume. and print it 5 entries strting and ending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4101b2d-0fec-48d1-98a1-790eac33f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  8 of 8 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^CNXNIITY']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Daily ETF and Index Data (Open, Close, Volume) ---\n",
      "\n",
      "Fetching data from Start Date: 2021-01-01 to End Date (exclusive): 2025-04-13\n",
      "(Data requested up to yesterday: 2025-04-12)\n",
      "\n",
      "Tickers to fetch: ['BANKBEES.NS', 'JUNIORBEES.NS', 'NIFTYBEES.NS', 'SENSEXBEES.BO', '^BSESN', '^CNXNIITY', '^NSEBANK', '^NSEI']\n",
      "\n",
      "Attempting to download data...\n",
      "\n",
      "Data download attempt complete. Processing columns...\n",
      " - Processed and stored Open, Close, Volume for BANKBEES.NS\n",
      " - Processed and stored Open, Close, Volume for JUNIORBEES.NS\n",
      " - Processed and stored Open, Close, Volume for NIFTYBEES.NS\n",
      " - Processed and stored Open, Close, Volume for SENSEXBEES.BO\n",
      " - Processed and stored Open, Close, Volume for ^BSESN\n",
      " - Warning: No valid data remained for ^CNXNIITY after cleaning.\n",
      " - Processed and stored Open, Close, Volume for ^NSEBANK\n",
      " - Processed and stored Open, Close, Volume for ^NSEI\n",
      "\n",
      "--- Fetched Data Summary (Head & Tail) ---\n",
      "Displaying Head(5) and Tail(5) for 7 successfully processed tickers:\n",
      "\n",
      "========================================\n",
      "Ticker: BANKBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 314.35 | 313.65  | 308206   |\n",
      "| 2021-01-04 00:00:00 | 316    | 314.12  | 737195   |\n",
      "| 2021-01-05 00:00:00 | 313.21 | 318.73  | 770683   |\n",
      "| 2021-01-06 00:00:00 | 320.64 | 319.67  | 608840   |\n",
      "| 2021-01-07 00:00:00 | 325    | 321.08  | 748450   |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume      |\n",
      "|:--------------------|:-------|:--------|:------------|\n",
      "| 2025-04-04 00:00:00 | 532    | 528.98  | 1.53491e+06 |\n",
      "| 2025-04-07 00:00:00 | 527    | 513.46  | 1.84104e+06 |\n",
      "| 2025-04-08 00:00:00 | 519.98 | 518.63  | 970866      |\n",
      "| 2025-04-09 00:00:00 | 515.02 | 516.11  | 886325      |\n",
      "| 2025-04-11 00:00:00 | 520.99 | 522.84  | 806992      |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: JUNIORBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 345    | 342.19  | 101472   |\n",
      "| 2021-01-04 00:00:00 | 354    | 346.62  | 94333    |\n",
      "| 2021-01-05 00:00:00 | 354    | 351.38  | 616888   |\n",
      "| 2021-01-06 00:00:00 | 359    | 353.29  | 87070    |\n",
      "| 2021-01-07 00:00:00 | 368.1  | 354.73  | 62490    |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume      |\n",
      "|:--------------------|:-------|:--------|:------------|\n",
      "| 2025-04-04 00:00:00 | 678.99 | 658.5   | 670078      |\n",
      "| 2025-04-07 00:00:00 | 678.25 | 640     | 1.81228e+06 |\n",
      "| 2025-04-08 00:00:00 | 659.2  | 651.09  | 530625      |\n",
      "| 2025-04-09 00:00:00 | 666.45 | 649.82  | 270401      |\n",
      "| 2025-04-11 00:00:00 | 669.3  | 658.32  | 486347      |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: NIFTYBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume      |\n",
      "|:--------------------|:-------|:--------|:------------|\n",
      "| 2021-01-01 00:00:00 | 159.68 | 149.57  | 767502      |\n",
      "| 2021-01-04 00:00:00 | 150.59 | 150.71  | 1.72907e+06 |\n",
      "| 2021-01-05 00:00:00 | 159.7  | 151.3   | 2.24852e+06 |\n",
      "| 2021-01-06 00:00:00 | 159.7  | 151.22  | 1.89016e+06 |\n",
      "| 2021-01-07 00:00:00 | 155    | 151.2   | 1.18483e+06 |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume      |\n",
      "|:--------------------|:-------|:--------|:------------|\n",
      "| 2025-04-04 00:00:00 | 260.48 | 257.16  | 9.23346e+06 |\n",
      "| 2025-04-07 00:00:00 | 264.85 | 249.1   | 3.46549e+07 |\n",
      "| 2025-04-08 00:00:00 | 256.55 | 252.72  | 9.86051e+06 |\n",
      "| 2025-04-09 00:00:00 | 251.72 | 251.03  | 7.14424e+06 |\n",
      "| 2025-04-11 00:00:00 | 255.99 | 255.97  | 1.08022e+07 |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: SENSEXBEES.BO\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 507.05 | 515.07  | 164      |\n",
      "| 2021-01-04 00:00:00 | 510    | 518.36  | 267      |\n",
      "| 2021-01-05 00:00:00 | 515    | 519.15  | 1026     |\n",
      "| 2021-01-06 00:00:00 | 525    | 520.77  | 206      |\n",
      "| 2021-01-07 00:00:00 | 523.04 | 518.25  | 32       |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 859    | 854.03  | 10273    |\n",
      "| 2025-04-07 00:00:00 | 851    | 827.2   | 29738    |\n",
      "| 2025-04-08 00:00:00 | 844.98 | 840.36  | 6291     |\n",
      "| 2025-04-09 00:00:00 | 844.98 | 835.57  | 2205     |\n",
      "| 2025-04-11 00:00:00 | 841.12 | 850.25  | 4319     |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^BSESN\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 47785.3 | 47869   | 82700    |\n",
      "| 2021-01-04 00:00:00 | 48109.2 | 48176.8 | 13900    |\n",
      "| 2021-01-05 00:00:00 | 48037.6 | 48437.8 | 12200    |\n",
      "| 2021-01-06 00:00:00 | 48616.7 | 48174.1 | 22500    |\n",
      "| 2021-01-07 00:00:00 | 48524.4 | 48093.3 | 18400    |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 76160.1 | 75364.7 | 11700    |\n",
      "| 2025-04-07 00:00:00 | 71449.9 | 73137.9 | 29400    |\n",
      "| 2025-04-08 00:00:00 | 74013.7 | 74227.1 | 17100    |\n",
      "| 2025-04-09 00:00:00 | 74103.8 | 73847.1 | 9100     |\n",
      "| 2025-04-11 00:00:00 | 74835.5 | 75157.3 | 14200    |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^NSEBANK\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-04 00:00:00 | 31484.8 | 31212.1 | 0        |\n",
      "| 2021-01-05 00:00:00 | 31040.7 | 31721.9 | 0        |\n",
      "| 2021-01-06 00:00:00 | 31839.6 | 31797.5 | 0        |\n",
      "| 2021-01-07 00:00:00 | 32129.4 | 31955.6 | 0        |\n",
      "| 2021-01-08 00:00:00 | 32297.7 | 32083.8 | 0        |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 51711.6 | 51502.7 | 189600   |\n",
      "| 2025-04-07 00:00:00 | 49336.1 | 49860.1 | 236800   |\n",
      "| 2025-04-08 00:00:00 | 50388.6 | 50511   | 162300   |\n",
      "| 2025-04-09 00:00:00 | 50487.1 | 50240.1 | 141800   |\n",
      "| 2025-04-11 00:00:00 | 50634.1 | 51002.4 | 140000   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^NSEI\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 13996.1 | 14018.5 | 358100   |\n",
      "| 2021-01-04 00:00:00 | 14104.3 | 14132.9 | 495000   |\n",
      "| 2021-01-05 00:00:00 | 14075.2 | 14199.5 | 492500   |\n",
      "| 2021-01-06 00:00:00 | 14241   | 14146.2 | 632300   |\n",
      "| 2021-01-07 00:00:00 | 14253.8 | 14137.3 | 559200   |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 23190.4 | 22904.4 | 466800   |\n",
      "| 2025-04-07 00:00:00 | 21758.4 | 22161.6 | 647100   |\n",
      "| 2025-04-08 00:00:00 | 22446.8 | 22535.8 | 468300   |\n",
      "| 2025-04-09 00:00:00 | 22460.3 | 22399.2 | 383800   |\n",
      "| 2025-04-11 00:00:00 | 22695.4 | 22828.6 | 402200   |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"--- Fetching Daily ETF and Index Data (Open, Close, Volume) ---\")\n",
    "\n",
    "# 1. Define the ETF to Underlying Index Mapping (Yahoo Finance Tickers)\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",      # Nifty 50 ETF vs Nifty 50 Index\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",   # Nifty Bank ETF vs Nifty Bank Index\n",
    "    \"JUNIORBEES.NS\": \"^CNXNIITY\", # Nifty Next 50 ETF vs Nifty Next 50 Index (*Corrected*)\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",    # Sensex ETF vs Sensex Index\n",
    "}\n",
    "# *Self-Correction Note:* Used likely intended Nifty Next 50 ticker \"^CNXNIITY\" for JuniorBeES.\n",
    "\n",
    "# 2. Define Date Range\n",
    "end_date = datetime.now().date() # Use today's date (Sunday, April 13, 2025)\n",
    "yesterday = end_date - timedelta(days=1) # Calculate yesterday (Saturday, April 12, 2025 - data up to Friday)\n",
    "start_date = datetime(2021, 1, 1).date()\n",
    "\n",
    "# Format dates as strings for yfinance\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "# yfinance 'end' date is exclusive, so use today's date to include yesterday's data\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nFetching data from Start Date: {start_str} to End Date (exclusive): {end_str}\")\n",
    "print(f\"(Data requested up to yesterday: {yesterday.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "# 3. Prepare list of all unique tickers to fetch\n",
    "all_tickers = list(etf_mapping_yf.keys()) + list(etf_mapping_yf.values())\n",
    "unique_tickers = sorted(list(set(all_tickers)))\n",
    "\n",
    "print(f\"\\nTickers to fetch: {unique_tickers}\")\n",
    "\n",
    "# 4. Fetch Data\n",
    "all_data = {} # Dictionary to store final processed dataframes (O, C, V)\n",
    "\n",
    "print(\"\\nAttempting to download data...\")\n",
    "try:\n",
    "    # Fetch all data columns initially\n",
    "    data_panel = yf.download(unique_tickers, start=start_str, end=end_str, progress=True)\n",
    "\n",
    "    if data_panel.empty:\n",
    "        print(\"\\nError: No data fetched. Check tickers and date range.\")\n",
    "    elif isinstance(data_panel.columns, pd.MultiIndex):\n",
    "        print(\"\\nData download attempt complete. Processing columns...\")\n",
    "        # Process and store individual DataFrames with selected columns\n",
    "        for ticker in unique_tickers:\n",
    "            # Check if ticker data exists in the multi-index columns\n",
    "            if ticker in data_panel.columns.get_level_values(1):\n",
    "                # Extract data for the specific ticker\n",
    "                df_ticker_full = data_panel.iloc[:, data_panel.columns.get_level_values(1)==ticker]\n",
    "                # Remove the top level ticker index from columns\n",
    "                df_ticker_full.columns = df_ticker_full.columns.droplevel(1)\n",
    "\n",
    "                # Select only 'Open', 'Close', 'Volume' columns\n",
    "                # Check if columns exist before selecting\n",
    "                cols_to_select = ['Open', 'Close', 'Volume']\n",
    "                available_cols = [col for col in cols_to_select if col in df_ticker_full.columns]\n",
    "\n",
    "                if 'Open' in available_cols and 'Close' in available_cols: # O/C are essential\n",
    "                    df_ticker_selected = df_ticker_full[available_cols].copy()\n",
    "                    # Remove rows where all selected values are NaN\n",
    "                    df_ticker_selected.dropna(how='all', inplace=True)\n",
    "                    # Optional: Remove rows where Open or Close is NaN\n",
    "                    df_ticker_selected.dropna(subset=['Open', 'Close'], how='any', inplace=True)\n",
    "\n",
    "                    if not df_ticker_selected.empty:\n",
    "                        all_data[ticker] = df_ticker_selected\n",
    "                        print(f\" - Processed and stored {', '.join(available_cols)} for {ticker}\")\n",
    "                    else:\n",
    "                        print(f\" - Warning: No valid data remained for {ticker} after cleaning.\")\n",
    "                else:\n",
    "                     print(f\" - Warning: Essential columns 'Open'/'Close' missing for {ticker}.\")\n",
    "            else:\n",
    "                 print(f\" - Warning: Could not find data for {ticker} in downloaded panel.\")\n",
    "    else:\n",
    "         # Handle case where only one ticker might have downloaded successfully\n",
    "         print(\"\\nData download attempt complete (possibly for a single ticker). Processing columns...\")\n",
    "         if not data_panel.empty:\n",
    "             # Assuming the single ticker is the only one requested or downloaded\n",
    "             ticker = unique_tickers[0] # Assumption\n",
    "             # Select only 'Open', 'Close', 'Volume' columns\n",
    "             cols_to_select = ['Open', 'Close', 'Volume']\n",
    "             available_cols = [col for col in cols_to_select if col in data_panel.columns]\n",
    "\n",
    "             if 'Open' in available_cols and 'Close' in available_cols:\n",
    "                 df_ticker_selected = data_panel[available_cols].copy()\n",
    "                 df_ticker_selected.dropna(how='all', inplace=True)\n",
    "                 df_ticker_selected.dropna(subset=['Open', 'Close'], how='any', inplace=True)\n",
    "                 if not df_ticker_selected.empty:\n",
    "                     all_data[ticker] = df_ticker_selected\n",
    "                     print(f\" - Processed and stored {', '.join(available_cols)} for {ticker}\")\n",
    "                 else:\n",
    "                     print(f\" - Warning: No valid data remained for {ticker} after cleaning.\")\n",
    "             else:\n",
    "                 print(f\" - Warning: Essential columns 'Open'/'Close' missing for {ticker}.\")\n",
    "         else:\n",
    "             print(\" - Fetched panel is empty.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during data fetching or processing: {e}\")\n",
    "    print(\"Please ensure libraries are installed and check internet connection.\")\n",
    "\n",
    "# 5. Print Head and Tail for each fetched DataFrame\n",
    "print(\"\\n--- Fetched Data Summary (Head & Tail) ---\")\n",
    "if all_data:\n",
    "    print(f\"Displaying Head(5) and Tail(5) for {len(all_data)} successfully processed tickers:\")\n",
    "    for ticker, df in all_data.items():\n",
    "        print(\"\\n========================================\")\n",
    "        print(f\"Ticker: {ticker}\")\n",
    "        print(\"========================================\")\n",
    "        print(\"--- Head ---\")\n",
    "        print(df.head(5).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "        print(\"\\n--- Tail ---\")\n",
    "        print(df.tail(5).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "        print(\"----------------------------------------\\n\")\n",
    "else:\n",
    "    print(\"No data was successfully processed and stored to display.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59fece09-452f-4a62-b44f-ea71dbcc709f",
   "metadata": {},
   "source": [
    "its rounding off underlying asset values, i dont want that. open and close with 2 decimal places and volume integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69e12447-72bd-47a8-a93e-3f738e16c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  8 of 8 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^CNXNIITY']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Daily ETF and Index Data (Open, Close, Volume) ---\n",
      "\n",
      "Fetching data from Start Date: 2021-01-01 to End Date (exclusive): 2025-04-13\n",
      "(Data requested up to yesterday: 2025-04-12)\n",
      "\n",
      "Tickers to fetch: ['BANKBEES.NS', 'JUNIORBEES.NS', 'NIFTYBEES.NS', 'SENSEXBEES.BO', '^BSESN', '^CNXNIITY', '^NSEBANK', '^NSEI']\n",
      "\n",
      "Attempting to download data...\n",
      "\n",
      "Data download attempt complete. Processing columns...\n",
      " - Processed and stored Open, Close, Volume for BANKBEES.NS\n",
      " - Processed and stored Open, Close, Volume for JUNIORBEES.NS\n",
      " - Processed and stored Open, Close, Volume for NIFTYBEES.NS\n",
      " - Processed and stored Open, Close, Volume for SENSEXBEES.BO\n",
      " - Processed and stored Open, Close, Volume for ^BSESN\n",
      " - Warning: No valid data remained for ^CNXNIITY after cleaning.\n",
      " - Processed and stored Open, Close, Volume for ^NSEBANK\n",
      " - Processed and stored Open, Close, Volume for ^NSEI\n",
      "\n",
      "--- Fetched Data Summary (Head & Tail with Formatting) ---\n",
      "Displaying Head(5) and Tail(5) for 7 successfully processed tickers:\n",
      "\n",
      "========================================\n",
      "Ticker: BANKBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for BANKBEES.NS: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 314.35 | 313.65  | 308206   |\n",
      "| 2021-01-04 00:00:00 | 316    | 314.12  | 737195   |\n",
      "| 2021-01-05 00:00:00 | 313.21 | 318.73  | 770683   |\n",
      "| 2021-01-06 00:00:00 | 320.64 | 319.67  | 608840   |\n",
      "| 2021-01-07 00:00:00 | 325    | 321.08  | 748450   |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for BANKBEES.NS: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 532    | 528.98  | 1534911  |\n",
      "| 2025-04-07 00:00:00 | 527    | 513.46  | 1841036  |\n",
      "| 2025-04-08 00:00:00 | 519.98 | 518.63  | 970866   |\n",
      "| 2025-04-09 00:00:00 | 515.02 | 516.11  | 886325   |\n",
      "| 2025-04-11 00:00:00 | 520.99 | 522.84  | 806992   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: JUNIORBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for JUNIORBEES.NS: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 345    | 342.19  | 101472   |\n",
      "| 2021-01-04 00:00:00 | 354    | 346.62  | 94333    |\n",
      "| 2021-01-05 00:00:00 | 354    | 351.38  | 616888   |\n",
      "| 2021-01-06 00:00:00 | 359    | 353.29  | 87070    |\n",
      "| 2021-01-07 00:00:00 | 368.1  | 354.73  | 62490    |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for JUNIORBEES.NS: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 678.99 | 658.5   | 670078   |\n",
      "| 2025-04-07 00:00:00 | 678.25 | 640     | 1812281  |\n",
      "| 2025-04-08 00:00:00 | 659.2  | 651.09  | 530625   |\n",
      "| 2025-04-09 00:00:00 | 666.45 | 649.82  | 270401   |\n",
      "| 2025-04-11 00:00:00 | 669.3  | 658.32  | 486347   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: NIFTYBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for NIFTYBEES.NS: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 159.68 | 149.57  | 767502   |\n",
      "| 2021-01-04 00:00:00 | 150.59 | 150.71  | 1729074  |\n",
      "| 2021-01-05 00:00:00 | 159.7  | 151.3   | 2248517  |\n",
      "| 2021-01-06 00:00:00 | 159.7  | 151.22  | 1890161  |\n",
      "| 2021-01-07 00:00:00 | 155    | 151.2   | 1184831  |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for NIFTYBEES.NS: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 260.48 | 257.16  | 9233464  |\n",
      "| 2025-04-07 00:00:00 | 264.85 | 249.1   | 34654934 |\n",
      "| 2025-04-08 00:00:00 | 256.55 | 252.72  | 9860513  |\n",
      "| 2025-04-09 00:00:00 | 251.72 | 251.03  | 7144236  |\n",
      "| 2025-04-11 00:00:00 | 255.99 | 255.97  | 10802170 |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: SENSEXBEES.BO\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for SENSEXBEES.BO: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 507.05 | 515.07  | 164      |\n",
      "| 2021-01-04 00:00:00 | 510    | 518.36  | 267      |\n",
      "| 2021-01-05 00:00:00 | 515    | 519.15  | 1026     |\n",
      "| 2021-01-06 00:00:00 | 525    | 520.77  | 206      |\n",
      "| 2021-01-07 00:00:00 | 523.04 | 518.25  | 32       |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for SENSEXBEES.BO: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 859    | 854.03  | 10273    |\n",
      "| 2025-04-07 00:00:00 | 851    | 827.2   | 29738    |\n",
      "| 2025-04-08 00:00:00 | 844.98 | 840.36  | 6291     |\n",
      "| 2025-04-09 00:00:00 | 844.98 | 835.57  | 2205     |\n",
      "| 2025-04-11 00:00:00 | 841.12 | 850.25  | 4319     |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^BSESN\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for ^BSESN: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 47785.3 | 47869   | 82700    |\n",
      "| 2021-01-04 00:00:00 | 48109.2 | 48176.8 | 13900    |\n",
      "| 2021-01-05 00:00:00 | 48037.6 | 48437.8 | 12200    |\n",
      "| 2021-01-06 00:00:00 | 48616.7 | 48174.1 | 22500    |\n",
      "| 2021-01-07 00:00:00 | 48524.4 | 48093.3 | 18400    |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for ^BSESN: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 76160.1 | 75364.7 | 11700    |\n",
      "| 2025-04-07 00:00:00 | 71449.9 | 73137.9 | 29400    |\n",
      "| 2025-04-08 00:00:00 | 74013.7 | 74227.1 | 17100    |\n",
      "| 2025-04-09 00:00:00 | 74103.8 | 73847.1 | 9100     |\n",
      "| 2025-04-11 00:00:00 | 74835.5 | 75157.3 | 14200    |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^NSEBANK\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for ^NSEBANK: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-04 00:00:00 | 31484.8 | 31212.1 | 0        |\n",
      "| 2021-01-05 00:00:00 | 31040.7 | 31721.9 | 0        |\n",
      "| 2021-01-06 00:00:00 | 31839.6 | 31797.5 | 0        |\n",
      "| 2021-01-07 00:00:00 | 32129.4 | 31955.6 | 0        |\n",
      "| 2021-01-08 00:00:00 | 32297.7 | 32083.8 | 0        |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for ^NSEBANK: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 51711.6 | 51502.7 | 189600   |\n",
      "| 2025-04-07 00:00:00 | 49336.1 | 49860.1 | 236800   |\n",
      "| 2025-04-08 00:00:00 | 50388.6 | 50511   | 162300   |\n",
      "| 2025-04-09 00:00:00 | 50487.1 | 50240.1 | 141800   |\n",
      "| 2025-04-11 00:00:00 | 50634.1 | 51002.4 | 140000   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^NSEI\n",
      "========================================\n",
      "--- Head ---\n",
      "Error formatting head for ^NSEI: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 13996.1 | 14018.5 | 358100   |\n",
      "| 2021-01-04 00:00:00 | 14104.3 | 14132.9 | 495000   |\n",
      "| 2021-01-05 00:00:00 | 14075.2 | 14199.5 | 492500   |\n",
      "| 2021-01-06 00:00:00 | 14241   | 14146.2 | 632300   |\n",
      "| 2021-01-07 00:00:00 | 14253.8 | 14137.3 | 559200   |\n",
      "\n",
      "--- Tail ---\n",
      "Error formatting tail for ^NSEI: 'Styler' object has no attribute 'to_markdown'. Printing raw:\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 23190.4 | 22904.4 | 466800   |\n",
      "| 2025-04-07 00:00:00 | 21758.4 | 22161.6 | 647100   |\n",
      "| 2025-04-08 00:00:00 | 22446.8 | 22535.8 | 468300   |\n",
      "| 2025-04-09 00:00:00 | 22460.3 | 22399.2 | 383800   |\n",
      "| 2025-04-11 00:00:00 | 22695.4 | 22828.6 | 402200   |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"--- Fetching Daily ETF and Index Data (Open, Close, Volume) ---\")\n",
    "\n",
    "# 1. Define the ETF to Underlying Index Mapping (Yahoo Finance Tickers)\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",      # Nifty 50 ETF vs Nifty 50 Index\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",   # Nifty Bank ETF vs Nifty Bank Index\n",
    "    \"JUNIORBEES.NS\": \"^CNXNIITY\", # Nifty Next 50 ETF vs Nifty Next 50 Index (*Corrected*)\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",    # Sensex ETF vs Sensex Index\n",
    "}\n",
    "# *Self-Correction Note:* Used likely intended Nifty Next 50 ticker \"^CNXNIITY\" for JuniorBeES.\n",
    "\n",
    "# 2. Define Date Range\n",
    "end_date = datetime.now().date() # Use today's date (Sunday, April 13, 2025)\n",
    "yesterday = end_date - timedelta(days=1) # Calculate yesterday (Saturday, April 12, 2025 - data up to Friday)\n",
    "start_date = datetime(2021, 1, 1).date()\n",
    "\n",
    "# Format dates as strings for yfinance\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "# yfinance 'end' date is exclusive, so use today's date to include yesterday's data\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nFetching data from Start Date: {start_str} to End Date (exclusive): {end_str}\")\n",
    "print(f\"(Data requested up to yesterday: {yesterday.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "# 3. Prepare list of all unique tickers to fetch\n",
    "all_tickers = list(etf_mapping_yf.keys()) + list(etf_mapping_yf.values())\n",
    "unique_tickers = sorted(list(set(all_tickers)))\n",
    "\n",
    "print(f\"\\nTickers to fetch: {unique_tickers}\")\n",
    "\n",
    "# 4. Fetch Data\n",
    "all_data = {} # Dictionary to store final processed dataframes (O, C, V)\n",
    "\n",
    "print(\"\\nAttempting to download data...\")\n",
    "try:\n",
    "    # Fetch all data columns initially\n",
    "    data_panel = yf.download(unique_tickers, start=start_str, end=end_str, progress=True)\n",
    "\n",
    "    if data_panel.empty:\n",
    "        print(\"\\nError: No data fetched. Check tickers and date range.\")\n",
    "    elif isinstance(data_panel.columns, pd.MultiIndex):\n",
    "        print(\"\\nData download attempt complete. Processing columns...\")\n",
    "        # Process and store individual DataFrames with selected columns\n",
    "        for ticker in unique_tickers:\n",
    "            # Check if ticker data exists in the multi-index columns\n",
    "            if ticker in data_panel.columns.get_level_values(1):\n",
    "                # Extract data for the specific ticker\n",
    "                df_ticker_full = data_panel.iloc[:, data_panel.columns.get_level_values(1)==ticker]\n",
    "                # Remove the top level ticker index from columns\n",
    "                df_ticker_full.columns = df_ticker_full.columns.droplevel(1)\n",
    "\n",
    "                # Select only 'Open', 'Close', 'Volume' columns\n",
    "                # Check if columns exist before selecting\n",
    "                cols_to_select = ['Open', 'Close', 'Volume']\n",
    "                available_cols = [col for col in cols_to_select if col in df_ticker_full.columns]\n",
    "\n",
    "                if 'Open' in available_cols and 'Close' in available_cols: # O/C are essential\n",
    "                    df_ticker_selected = df_ticker_full[available_cols].copy()\n",
    "                    # Remove rows where all selected values are NaN\n",
    "                    df_ticker_selected.dropna(how='all', inplace=True)\n",
    "                    # Optional: Remove rows where Open or Close is NaN\n",
    "                    df_ticker_selected.dropna(subset=['Open', 'Close'], how='any', inplace=True)\n",
    "\n",
    "                    # Attempt to convert Volume to integer type if it exists and is suitable\n",
    "                    if 'Volume' in df_ticker_selected.columns:\n",
    "                        # Use Int64 (nullable integer) to handle potential NaNs if any remain\n",
    "                        df_ticker_selected['Volume'] = pd.to_numeric(df_ticker_selected['Volume'], errors='coerce').astype('Int64')\n",
    "\n",
    "                    if not df_ticker_selected.empty:\n",
    "                        all_data[ticker] = df_ticker_selected\n",
    "                        print(f\" - Processed and stored {', '.join(available_cols)} for {ticker}\")\n",
    "                    else:\n",
    "                        print(f\" - Warning: No valid data remained for {ticker} after cleaning.\")\n",
    "                else:\n",
    "                     print(f\" - Warning: Essential columns 'Open'/'Close' missing for {ticker}.\")\n",
    "            else:\n",
    "                 print(f\" - Warning: Could not find data for {ticker} in downloaded panel.\")\n",
    "    else:\n",
    "         # Handle case where only one ticker might have downloaded successfully\n",
    "         print(\"\\nData download attempt complete (possibly for a single ticker). Processing columns...\")\n",
    "         if not data_panel.empty:\n",
    "             # Assuming the single ticker is the only one requested or downloaded\n",
    "             ticker = unique_tickers[0] # Assumption\n",
    "             # Select only 'Open', 'Close', 'Volume' columns\n",
    "             cols_to_select = ['Open', 'Close', 'Volume']\n",
    "             available_cols = [col for col in cols_to_select if col in data_panel.columns]\n",
    "\n",
    "             if 'Open' in available_cols and 'Close' in available_cols:\n",
    "                 df_ticker_selected = data_panel[available_cols].copy()\n",
    "                 df_ticker_selected.dropna(how='all', inplace=True)\n",
    "                 df_ticker_selected.dropna(subset=['Open', 'Close'], how='any', inplace=True)\n",
    "\n",
    "                 # Attempt to convert Volume to integer type\n",
    "                 if 'Volume' in df_ticker_selected.columns:\n",
    "                    df_ticker_selected['Volume'] = pd.to_numeric(df_ticker_selected['Volume'], errors='coerce').astype('Int64')\n",
    "\n",
    "                 if not df_ticker_selected.empty:\n",
    "                     all_data[ticker] = df_ticker_selected\n",
    "                     print(f\" - Processed and stored {', '.join(available_cols)} for {ticker}\")\n",
    "                 else:\n",
    "                     print(f\" - Warning: No valid data remained for {ticker} after cleaning.\")\n",
    "             else:\n",
    "                 print(f\" - Warning: Essential columns 'Open'/'Close' missing for {ticker}.\")\n",
    "         else:\n",
    "             print(\" - Fetched panel is empty.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during data fetching or processing: {e}\")\n",
    "    print(\"Please ensure libraries are installed and check internet connection.\")\n",
    "\n",
    "# 5. Print Head and Tail for each fetched DataFrame with Formatting\n",
    "print(\"\\n--- Fetched Data Summary (Head & Tail with Formatting) ---\")\n",
    "if all_data:\n",
    "    print(f\"Displaying Head(5) and Tail(5) for {len(all_data)} successfully processed tickers:\")\n",
    "    for ticker, df in all_data.items():\n",
    "        print(\"\\n========================================\")\n",
    "        print(f\"Ticker: {ticker}\")\n",
    "        print(\"========================================\")\n",
    "\n",
    "        # Define formatters based on existing columns\n",
    "        format_dict = {}\n",
    "        if 'Open' in df.columns:\n",
    "            format_dict['Open'] = '{:.2f}'  # Format Open to 2 decimal places\n",
    "        if 'Close' in df.columns:\n",
    "            format_dict['Close'] = '{:.2f}' # Format Close to 2 decimal places\n",
    "        if 'Volume' in df.columns:\n",
    "             # Format Volume as integer with thousands separator\n",
    "             format_dict['Volume'] = '{:,.0f}'\n",
    "\n",
    "        # Apply formatting using Styler and print head\n",
    "        print(\"--- Head ---\")\n",
    "        try:\n",
    "            # Apply formatting to the slice being printed\n",
    "            print(df.head(5).style.format(format_dict).to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "        except Exception as e:\n",
    "            print(f\"Error formatting head for {ticker}: {e}. Printing raw:\")\n",
    "            print(df.head(5).to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "\n",
    "\n",
    "        # Apply formatting using Styler and print tail\n",
    "        print(\"\\n--- Tail ---\")\n",
    "        try:\n",
    "             # Apply formatting to the slice being printed\n",
    "             print(df.tail(5).style.format(format_dict).to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "        except Exception as e:\n",
    "            print(f\"Error formatting tail for {ticker}: {e}. Printing raw:\")\n",
    "            print(df.tail(5).to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "\n",
    "        print(\"----------------------------------------\\n\")\n",
    "else:\n",
    "    print(\"No data was successfully processed and stored to display.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cea93e0-671f-473c-89e9-11393dd869c1",
   "metadata": {},
   "source": [
    "above output (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2660b688-a520-4685-8624-f5c2fbc5b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  8 of 8 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^CNXNIITY']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Daily ETF and Index Data (Open, Close, Volume) ---\n",
      "\n",
      "Fetching data from Start Date: 2021-01-01 to End Date (exclusive): 2025-04-13\n",
      "(Data requested up to yesterday: 2025-04-12)\n",
      "\n",
      "Tickers to fetch: ['BANKBEES.NS', 'JUNIORBEES.NS', 'NIFTYBEES.NS', 'SENSEXBEES.BO', '^BSESN', '^CNXNIITY', '^NSEBANK', '^NSEI']\n",
      "\n",
      "Attempting to download data...\n",
      "\n",
      "Warning: Ticker ^CNXNIITY contained only NaN values and might be causing issues.\n",
      "\n",
      "Data download attempt complete. Processing columns...\n",
      " - Processed and stored Open, Close, Volume for BANKBEES.NS\n",
      " - Processed and stored Open, Close, Volume for JUNIORBEES.NS\n",
      " - Processed and stored Open, Close, Volume for NIFTYBEES.NS\n",
      " - Processed and stored Open, Close, Volume for SENSEXBEES.BO\n",
      " - Processed and stored Open, Close, Volume for ^BSESN\n",
      " - Warning: No valid data remained for ^CNXNIITY after cleaning.\n",
      " - Processed and stored Open, Close, Volume for ^NSEBANK\n",
      " - Processed and stored Open, Close, Volume for ^NSEI\n",
      "\n",
      "--- Fetched Data Summary (Head & Tail with Formatting) ---\n",
      "Displaying Head(5) and Tail(5) for 7 successfully processed tickers:\n",
      "\n",
      "========================================\n",
      "Ticker: BANKBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 314.35 | 313.65  | 308,206  |\n",
      "| 2021-01-04 00:00:00 | 316    | 314.12  | 737,195  |\n",
      "| 2021-01-05 00:00:00 | 313.21 | 318.73  | 770,683  |\n",
      "| 2021-01-06 00:00:00 | 320.64 | 319.67  | 608,840  |\n",
      "| 2021-01-07 00:00:00 | 325    | 321.08  | 748,450  |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume    |\n",
      "|:--------------------|:-------|:--------|:----------|\n",
      "| 2025-04-04 00:00:00 | 532    | 528.98  | 1,534,911 |\n",
      "| 2025-04-07 00:00:00 | 527    | 513.46  | 1,841,036 |\n",
      "| 2025-04-08 00:00:00 | 519.98 | 518.63  | 970,866   |\n",
      "| 2025-04-09 00:00:00 | 515.02 | 516.11  | 886,325   |\n",
      "| 2025-04-11 00:00:00 | 520.99 | 522.84  | 806,992   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: JUNIORBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 345    | 342.19  | 101,472  |\n",
      "| 2021-01-04 00:00:00 | 354    | 346.62  | 94,333   |\n",
      "| 2021-01-05 00:00:00 | 354    | 351.38  | 616,888  |\n",
      "| 2021-01-06 00:00:00 | 359    | 353.29  | 87,070   |\n",
      "| 2021-01-07 00:00:00 | 368.1  | 354.73  | 62,490   |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume    |\n",
      "|:--------------------|:-------|:--------|:----------|\n",
      "| 2025-04-04 00:00:00 | 678.99 | 658.5   | 670,078   |\n",
      "| 2025-04-07 00:00:00 | 678.25 | 640     | 1,812,281 |\n",
      "| 2025-04-08 00:00:00 | 659.2  | 651.09  | 530,625   |\n",
      "| 2025-04-09 00:00:00 | 666.45 | 649.82  | 270,401   |\n",
      "| 2025-04-11 00:00:00 | 669.3  | 658.32  | 486,347   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: NIFTYBEES.NS\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume    |\n",
      "|:--------------------|:-------|:--------|:----------|\n",
      "| 2021-01-01 00:00:00 | 159.68 | 149.57  | 767,502   |\n",
      "| 2021-01-04 00:00:00 | 150.59 | 150.71  | 1,729,074 |\n",
      "| 2021-01-05 00:00:00 | 159.7  | 151.3   | 2,248,517 |\n",
      "| 2021-01-06 00:00:00 | 159.7  | 151.22  | 1,890,161 |\n",
      "| 2021-01-07 00:00:00 | 155    | 151.2   | 1,184,831 |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume     |\n",
      "|:--------------------|:-------|:--------|:-----------|\n",
      "| 2025-04-04 00:00:00 | 260.48 | 257.16  | 9,233,464  |\n",
      "| 2025-04-07 00:00:00 | 264.85 | 249.1   | 34,654,934 |\n",
      "| 2025-04-08 00:00:00 | 256.55 | 252.72  | 9,860,513  |\n",
      "| 2025-04-09 00:00:00 | 251.72 | 251.03  | 7,144,236  |\n",
      "| 2025-04-11 00:00:00 | 255.99 | 255.97  | 10,802,170 |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: SENSEXBEES.BO\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 507.05 | 515.07  | 164      |\n",
      "| 2021-01-04 00:00:00 | 510    | 518.36  | 267      |\n",
      "| 2021-01-05 00:00:00 | 515    | 519.15  | 1,026    |\n",
      "| 2021-01-06 00:00:00 | 525    | 520.77  | 206      |\n",
      "| 2021-01-07 00:00:00 | 523.04 | 518.25  | 32       |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open   | Close   | Volume   |\n",
      "|:--------------------|:-------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 859    | 854.03  | 10,273   |\n",
      "| 2025-04-07 00:00:00 | 851    | 827.2   | 29,738   |\n",
      "| 2025-04-08 00:00:00 | 844.98 | 840.36  | 6,291    |\n",
      "| 2025-04-09 00:00:00 | 844.98 | 835.57  | 2,205    |\n",
      "| 2025-04-11 00:00:00 | 841.12 | 850.25  | 4,319    |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^BSESN\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 47785.3 | 47869   | 82,700   |\n",
      "| 2021-01-04 00:00:00 | 48109.2 | 48176.8 | 13,900   |\n",
      "| 2021-01-05 00:00:00 | 48037.6 | 48437.8 | 12,200   |\n",
      "| 2021-01-06 00:00:00 | 48616.7 | 48174.1 | 22,500   |\n",
      "| 2021-01-07 00:00:00 | 48524.4 | 48093.3 | 18,400   |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 76160.1 | 75364.7 | 11,700   |\n",
      "| 2025-04-07 00:00:00 | 71449.9 | 73137.9 | 29,400   |\n",
      "| 2025-04-08 00:00:00 | 74013.7 | 74227.1 | 17,100   |\n",
      "| 2025-04-09 00:00:00 | 74103.8 | 73847.1 | 9,100    |\n",
      "| 2025-04-11 00:00:00 | 74835.5 | 75157.3 | 14,200   |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^NSEBANK\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-04 00:00:00 | 31484.8 | 31212.1 | 0        |\n",
      "| 2021-01-05 00:00:00 | 31040.7 | 31721.9 | 0        |\n",
      "| 2021-01-06 00:00:00 | 31839.6 | 31797.5 | 0        |\n",
      "| 2021-01-07 00:00:00 | 32129.4 | 31955.6 | 0        |\n",
      "| 2021-01-08 00:00:00 | 32297.7 | 32083.8 | 0        |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 51711.6 | 51502.7 | 189,600  |\n",
      "| 2025-04-07 00:00:00 | 49336.1 | 49860.1 | 236,800  |\n",
      "| 2025-04-08 00:00:00 | 50388.6 | 50511   | 162,300  |\n",
      "| 2025-04-09 00:00:00 | 50487.1 | 50240.2 | 141,800  |\n",
      "| 2025-04-11 00:00:00 | 50634.1 | 51002.3 | 140,000  |\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "Ticker: ^NSEI\n",
      "========================================\n",
      "--- Head ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2021-01-01 00:00:00 | 13996.1 | 14018.5 | 358,100  |\n",
      "| 2021-01-04 00:00:00 | 14104.4 | 14132.9 | 495,000  |\n",
      "| 2021-01-05 00:00:00 | 14075.1 | 14199.5 | 492,500  |\n",
      "| 2021-01-06 00:00:00 | 14241   | 14146.2 | 632,300  |\n",
      "| 2021-01-07 00:00:00 | 14253.8 | 14137.4 | 559,200  |\n",
      "\n",
      "--- Tail ---\n",
      "| Date                | Open    | Close   | Volume   |\n",
      "|:--------------------|:--------|:--------|:---------|\n",
      "| 2025-04-04 00:00:00 | 23190.4 | 22904.5 | 466,800  |\n",
      "| 2025-04-07 00:00:00 | 21758.4 | 22161.6 | 647,100  |\n",
      "| 2025-04-08 00:00:00 | 22446.8 | 22535.8 | 468,300  |\n",
      "| 2025-04-09 00:00:00 | 22460.3 | 22399.2 | 383,800  |\n",
      "| 2025-04-11 00:00:00 | 22695.4 | 22828.5 | 402,200  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"--- Fetching Daily ETF and Index Data (Open, Close, Volume) ---\")\n",
    "\n",
    "# 1. Define the ETF to Underlying Index Mapping (Yahoo Finance Tickers)\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",      # Nifty 50 ETF vs Nifty 50 Index\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",   # Nifty Bank ETF vs Nifty Bank Index\n",
    "    \"JUNIORBEES.NS\": \"^CNXNIITY\", # Nifty Next 50 ETF vs Nifty Next 50 Index (*Corrected*)\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",    # Sensex ETF vs Sensex Index\n",
    "}\n",
    "# *Self-Correction Note:* Used likely intended Nifty Next 50 ticker \"^CNXNIITY\" for JuniorBeES.\n",
    "\n",
    "# 2. Define Date Range\n",
    "end_date = datetime.now().date() # Use today's date (Sunday, April 13, 2025)\n",
    "yesterday = end_date - timedelta(days=1) # Calculate yesterday (Saturday, April 12, 2025 - data up to Friday)\n",
    "start_date = datetime(2021, 1, 1).date()\n",
    "\n",
    "# Format dates as strings for yfinance\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "# yfinance 'end' date is exclusive, so use today's date to include yesterday's data\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nFetching data from Start Date: {start_str} to End Date (exclusive): {end_str}\")\n",
    "print(f\"(Data requested up to yesterday: {yesterday.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "# 3. Prepare list of all unique tickers to fetch\n",
    "all_tickers = list(etf_mapping_yf.keys()) + list(etf_mapping_yf.values())\n",
    "unique_tickers = sorted(list(set(all_tickers)))\n",
    "\n",
    "print(f\"\\nTickers to fetch: {unique_tickers}\")\n",
    "\n",
    "# 4. Fetch Data\n",
    "all_data = {} # Dictionary to store final processed dataframes (O, C, V)\n",
    "\n",
    "print(\"\\nAttempting to download data...\")\n",
    "try:\n",
    "    # Fetch all data columns initially\n",
    "    # Provide feedback by setting progress=True\n",
    "    data_panel = yf.download(unique_tickers, start=start_str, end=end_str, progress=True)\n",
    "\n",
    "    # Check specifically for the known problematic ticker\n",
    "    if '^CNXNIITY' in data_panel.columns.get_level_values(1):\n",
    "         # Check if all values for the problematic ticker are NaN which might cause the error observed\n",
    "         if data_panel.xs('^CNXNIITY', axis=1, level=1).isnull().all().all():\n",
    "              print(\"\\nWarning: Ticker ^CNXNIITY contained only NaN values and might be causing issues.\")\n",
    "\n",
    "\n",
    "    if data_panel.empty:\n",
    "        print(\"\\nError: No data fetched. Check tickers and date range.\")\n",
    "    # Check if it's a MultiIndex DataFrame (multiple tickers downloaded)\n",
    "    elif isinstance(data_panel.columns, pd.MultiIndex):\n",
    "        print(\"\\nData download attempt complete. Processing columns...\")\n",
    "        # Process and store individual DataFrames with selected columns\n",
    "        for ticker in unique_tickers:\n",
    "            # Check if ticker data exists in the multi-index columns\n",
    "            if ticker in data_panel.columns.get_level_values(1):\n",
    "                # Extract data for the specific ticker\n",
    "                df_ticker_full = data_panel.iloc[:, data_panel.columns.get_level_values(1)==ticker]\n",
    "                # Remove the top level ticker index from columns\n",
    "                df_ticker_full.columns = df_ticker_full.columns.droplevel(1)\n",
    "\n",
    "                # Select only 'Open', 'Close', 'Volume' columns\n",
    "                # Check if columns exist before selecting\n",
    "                cols_to_select = ['Open', 'Close', 'Volume']\n",
    "                available_cols = [col for col in cols_to_select if col in df_ticker_full.columns]\n",
    "\n",
    "                if 'Open' in available_cols and 'Close' in available_cols: # O/C are essential\n",
    "                    df_ticker_selected = df_ticker_full[available_cols].copy()\n",
    "                    # Remove rows where all selected values are NaN\n",
    "                    df_ticker_selected.dropna(how='all', inplace=True)\n",
    "                    # Optional: Remove rows where Open or Close is NaN\n",
    "                    df_ticker_selected.dropna(subset=['Open', 'Close'], how='any', inplace=True)\n",
    "\n",
    "                    # Attempt to convert Volume to integer type if it exists and is suitable\n",
    "                    if 'Volume' in df_ticker_selected.columns:\n",
    "                        # Use Int64 (nullable integer) to handle potential NaNs if any remain\n",
    "                        df_ticker_selected['Volume'] = pd.to_numeric(df_ticker_selected['Volume'], errors='coerce').astype('Int64')\n",
    "\n",
    "                    if not df_ticker_selected.empty:\n",
    "                        all_data[ticker] = df_ticker_selected\n",
    "                        print(f\" - Processed and stored {', '.join(available_cols)} for {ticker}\")\n",
    "                    else:\n",
    "                        print(f\" - Warning: No valid data remained for {ticker} after cleaning.\")\n",
    "                else:\n",
    "                     print(f\" - Warning: Essential columns 'Open'/'Close' missing for {ticker}.\")\n",
    "            else:\n",
    "                 # This handles cases where download might fail specifically for one ticker in the list\n",
    "                 # e.g., the ^CNXNIITY failure observed\n",
    "                 print(f\" - Info: Data for ticker {ticker} was not found in the downloaded panel (may have failed download).\")\n",
    "    else:\n",
    "         # Handle case where only one ticker might have downloaded successfully (DataFrame, not MultiIndex)\n",
    "         print(\"\\nData download attempt complete (possibly for a single ticker). Processing columns...\")\n",
    "         if not data_panel.empty:\n",
    "             # Assuming the single ticker is the only one requested or downloaded\n",
    "             ticker = unique_tickers[0] # Assumption\n",
    "             # Select only 'Open', 'Close', 'Volume' columns\n",
    "             cols_to_select = ['Open', 'Close', 'Volume']\n",
    "             available_cols = [col for col in cols_to_select if col in data_panel.columns]\n",
    "\n",
    "             if 'Open' in available_cols and 'Close' in available_cols:\n",
    "                 df_ticker_selected = data_panel[available_cols].copy()\n",
    "                 df_ticker_selected.dropna(how='all', inplace=True)\n",
    "                 df_ticker_selected.dropna(subset=['Open', 'Close'], how='any', inplace=True)\n",
    "\n",
    "                 # Attempt to convert Volume to integer type\n",
    "                 if 'Volume' in df_ticker_selected.columns:\n",
    "                    df_ticker_selected['Volume'] = pd.to_numeric(df_ticker_selected['Volume'], errors='coerce').astype('Int64')\n",
    "\n",
    "                 if not df_ticker_selected.empty:\n",
    "                     all_data[ticker] = df_ticker_selected\n",
    "                     print(f\" - Processed and stored {', '.join(available_cols)} for {ticker}\")\n",
    "                 else:\n",
    "                     print(f\" - Warning: No valid data remained for {ticker} after cleaning.\")\n",
    "             else:\n",
    "                 print(f\" - Warning: Essential columns 'Open'/'Close' missing for {ticker}.\")\n",
    "         else:\n",
    "             print(\" - Fetched panel is empty.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during data fetching or processing: {e}\")\n",
    "    print(\"Please ensure libraries are installed and check internet connection.\")\n",
    "\n",
    "# 5. Print Head and Tail for each fetched DataFrame with Formatting\n",
    "print(\"\\n--- Fetched Data Summary (Head & Tail with Formatting) ---\")\n",
    "if all_data:\n",
    "    print(f\"Displaying Head(5) and Tail(5) for {len(all_data)} successfully processed tickers:\")\n",
    "    for ticker, df in all_data.items():\n",
    "        print(\"\\n========================================\")\n",
    "        print(f\"Ticker: {ticker}\")\n",
    "        print(\"========================================\")\n",
    "\n",
    "        # Create copies to apply formatting for display only\n",
    "        df_head = df.head(5).copy()\n",
    "        df_tail = df.tail(5).copy()\n",
    "\n",
    "        # Apply formatting using .map() or .apply()\n",
    "        try:\n",
    "            if 'Open' in df_head.columns:\n",
    "                df_head['Open'] = df_head['Open'].map('{:.2f}'.format)\n",
    "                df_tail['Open'] = df_tail['Open'].map('{:.2f}'.format)\n",
    "            if 'Close' in df_head.columns:\n",
    "                df_head['Close'] = df_head['Close'].map('{:.2f}'.format)\n",
    "                df_tail['Close'] = df_tail['Close'].map('{:.2f}'.format)\n",
    "            if 'Volume' in df_head.columns:\n",
    "                # Use apply with lambda to handle potential <NA> values from Int64 type\n",
    "                int_formatter = lambda x: '{:,.0f}'.format(x) if pd.notna(x) else '' # Format as int with comma, or empty string if NA\n",
    "                df_head['Volume'] = df_head['Volume'].apply(int_formatter)\n",
    "                df_tail['Volume'] = df_tail['Volume'].apply(int_formatter)\n",
    "\n",
    "            # Print formatted head and tail using to_markdown\n",
    "            print(\"--- Head ---\")\n",
    "            print(df_head.to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "            print(\"\\n--- Tail ---\")\n",
    "            print(df_tail.to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "\n",
    "        except Exception as e:\n",
    "            # Fallback if formatting fails for any reason\n",
    "            print(f\"Error during formatting/printing for {ticker}: {e}. Printing raw:\")\n",
    "            print(\"--- Head (Raw) ---\")\n",
    "            print(df.head(5).to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "            print(\"\\n--- Tail (Raw) ---\")\n",
    "            print(df.tail(5).to_markdown(numalign=\"left\", stralign=\"left\", index=True))\n",
    "\n",
    "        print(\"----------------------------------------\\n\")\n",
    "else:\n",
    "    print(\"No data was successfully processed and stored to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb5f378-f8b1-4d93-acb5-0bcf220294a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simplified ETF Data Fetch & Close Price Regression ---\n",
      "\n",
      "Date Range: 2021-01-01 to 2025-04-12\n",
      "\n",
      "--- Starting Data Fetch and Regression for each pair ---\n",
      "\n",
      "Processing Pair: ETF=NIFTYBEES.NS, Index=^NSEI\n",
      " - Warning: Missing Close data for pair NIFTYBEES.NS/^NSEI.\n",
      "\n",
      "Processing Pair: ETF=BANKBEES.NS, Index=^NSEBANK\n",
      " - Warning: Missing Close data for pair BANKBEES.NS/^NSEBANK.\n",
      "\n",
      "Processing Pair: ETF=JUNIORBEES.NS, Index=^NSMIDCP\n",
      " - Warning: Missing Close data for pair JUNIORBEES.NS/^NSMIDCP.\n",
      "\n",
      "Processing Pair: ETF=SENSEXBEES.BO, Index=^BSESN\n",
      " - Warning: Missing Close data for pair SENSEXBEES.BO/^BSESN.\n",
      "\n",
      "--- Analysis Complete ---\n",
      "\n",
      "Final Regression Results (Close Prices):\n",
      "No regression results were successfully calculated.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"--- Simplified ETF Data Fetch & Close Price Regression ---\")\n",
    "\n",
    "# 1. Define the ETF to Underlying Index Mapping (Yahoo Finance Tickers)\n",
    "# Using the exact dictionary you provided\n",
    "etf_mapping_yf = {\n",
    "    \"NIFTYBEES.NS\": \"^NSEI\",\n",
    "    \"BANKBEES.NS\": \"^NSEBANK\",\n",
    "    \"JUNIORBEES.NS\": \"^NSMIDCP\", # As provided by user\n",
    "    \"SENSEXBEES.BO\": \"^BSESN\",\n",
    "}\n",
    "\n",
    "# 2. Define Date Range\n",
    "end_date_dt = datetime.now().date() # Use today's date (Sunday, April 13, 2025)\n",
    "yesterday_dt = end_date_dt - timedelta(days=1) # Calculate yesterday\n",
    "start_date_dt = datetime(2021, 1, 1).date()\n",
    "\n",
    "# Format dates as strings for yfinance\n",
    "start_str = start_date_dt.strftime('%Y-%m-%d')\n",
    "# yfinance 'end' date is exclusive, use today's date to include yesterday\n",
    "end_str = end_date_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nDate Range: {start_str} to {yesterday_dt.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Dictionary to potentially store data (optional, focus is on regression here)\n",
    "# all_data = {}\n",
    "regression_results = {}\n",
    "\n",
    "print(\"\\n--- Starting Data Fetch and Regression for each pair ---\")\n",
    "\n",
    "# 3. Loop through ETF-Index pairs, fetch data, and run regression\n",
    "for etf_ticker, index_ticker in etf_mapping_yf.items():\n",
    "    print(f\"\\nProcessing Pair: ETF={etf_ticker}, Index={index_ticker}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch data for the pair\n",
    "        tickers_to_fetch = [etf_ticker, index_ticker]\n",
    "        data = yf.download(tickers_to_fetch, start=start_str, end=end_str, progress=False)\n",
    "\n",
    "        # Check if data was downloaded and has expected columns\n",
    "        if data.empty or not isinstance(data.columns, pd.MultiIndex):\n",
    "            print(f\" - Warning: Could not download or process data for pair {etf_ticker}/{index_ticker}.\")\n",
    "            continue # Skip to next pair\n",
    "\n",
    "        # Extract relevant columns (Open, Close, Volume) for both tickers\n",
    "        df_pair = data[['Open', 'Close', 'Volume']].copy()\n",
    "        # Flatten multi-index columns: e.g., ('Close', 'NIFTYBEES.NS') -> 'NIFTYBEES.NS_Close'\n",
    "        df_pair.columns = ['_'.join(col).strip() for col in df_pair.columns.values]\n",
    "\n",
    "        # Define column names based on fetched tickers\n",
    "        etf_close_col = f'{etf_ticker}_Close'\n",
    "        index_close_col = f'{index_ticker}_Close'\n",
    "\n",
    "        # Check if required columns exist after flattening\n",
    "        if etf_close_col not in df_pair.columns or index_close_col not in df_pair.columns:\n",
    "             print(f\" - Warning: Missing Close data for pair {etf_ticker}/{index_ticker}.\")\n",
    "             continue\n",
    "\n",
    "        # Keep only necessary close columns for regression and drop rows with NA in these columns\n",
    "        df_regr = df_pair[[etf_close_col, index_close_col]].dropna()\n",
    "\n",
    "        if len(df_regr) < 10: # Check if enough data points for meaningful regression\n",
    "             print(f\" - Warning: Not enough overlapping data points ({len(df_regr)}) for regression for {etf_ticker}/{index_ticker}.\")\n",
    "             continue\n",
    "\n",
    "        # Optional: Store the OCV data if needed later\n",
    "        # all_data[etf_ticker] = df_pair[[f'{etf_ticker}_Open', etf_close_col, f'{etf_ticker}_Volume']].dropna()\n",
    "        # all_data[index_ticker] = df_pair[[f'{index_ticker}_Open', index_close_col, f'{index_ticker}_Volume']].dropna()\n",
    "\n",
    "        # --- Perform Linear Regression on Closing Prices ---\n",
    "        # Y = ETF Close (Dependent)\n",
    "        # X = Index Close (Independent)\n",
    "        Y = df_regr[etf_close_col]\n",
    "        X = df_regr[index_close_col]\n",
    "        X = sm.add_constant(X) # Add constant intercept term (Alpha)\n",
    "\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "\n",
    "        # Extract results\n",
    "        alpha = model.params['const']\n",
    "        beta = model.params[index_close_col] # Get Beta coefficient\n",
    "\n",
    "        regression_results[etf_ticker] = {'alpha': alpha, 'beta': beta, 'R_squared': model.rsquared}\n",
    "\n",
    "        print(f\" - Regression Results ({etf_ticker} ~ {index_ticker}):\")\n",
    "        print(f\"   - Alpha: {alpha:.6f}\")\n",
    "        print(f\"   - Beta:  {beta:.6f}\")\n",
    "        print(f\"   - R-squared: {model.rsquared:.4f}\")\n",
    "        # Optional: print(model.summary())\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" - Error processing pair {etf_ticker}/{index_ticker}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Analysis Complete ---\")\n",
    "print(\"\\nFinal Regression Results (Close Prices):\")\n",
    "# Print summary of results stored\n",
    "if regression_results:\n",
    "    for etf, results in regression_results.items():\n",
    "         print(f\"- {etf}: Alpha={results['alpha']:.6f}, Beta={results['beta']:.6f}, R^2={results['R_squared']:.4f}\")\n",
    "else:\n",
    "    print(\"No regression results were successfully calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b860d-c57d-492f-b0dd-a53aab3bb56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
